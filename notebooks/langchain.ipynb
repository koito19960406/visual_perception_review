{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1584, which is longer than the specified 1000\n",
      "Created a chunk of size 1348, which is longer than the specified 1000\n",
      "Created a chunk of size 2246, which is longer than the specified 1000\n",
      "Created a chunk of size 1456, which is longer than the specified 1000\n",
      "Created a chunk of size 1319, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1133, which is longer than the specified 1000\n",
      "Created a chunk of size 1327, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1073, which is longer than the specified 1000\n",
      "Created a chunk of size 1210, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n",
      "Created a chunk of size 1020, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The availability of the data used in this study is not mentioned.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "import os\n",
    "import dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "loader = UnstructuredPDFLoader(\"notebooks/ijgi-11-00628-v2.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=OPENAI_API_KEY, temperature = 0, model_name = \"gpt-3.5-turbo-16k\"), chain_type=\"stuff\", retriever=docsearch.as_retriever(), chain_type_kwargs=chain_type_kwargs, return_source_documents = True)\n",
    "query = \"\"\"\n",
    "Choose the availability of the data used in this study from the following options: data vailable via URL, data available upon request, data is not available, not mentioned. The URL need to be a link to the whole dataset used by the author via a data host service, such as Google Drive (https://drive.google.com/), Harvard Dataverse (https://dataverse.harvard.edu/), Figshare (https://figshare.com/). Other type of URLs (e.g., social media data provider) should not be considered. \n",
    "Example Answer: \n",
    "------\n",
    "*XXX*\n",
    "------\n",
    "\"\"\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
