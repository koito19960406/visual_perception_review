{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "# check the existing papers in input_path = \"data/raw/all_papers\" and data/processed/3rd_run/input_df_with_title_doi_edited.xlsx\n",
    "# get the base names of the files\n",
    "file_list = [os.path.basename(file) for file in glob.glob(\"data/raw/all_papers/*\")]\n",
    "paper_df = pd.read_excel(\"data/processed/3rd_run/input_df_with_title_doi_edited.xlsx\")\n",
    "paper_file_list = paper_df[\"0\"].tolist()\n",
    "# list the papers that are not in file_list\n",
    "paper_list = [paper for paper in paper_file_list if paper not in file_list]\n",
    "# get rows of paper_df with paper_list\n",
    "paper_df = paper_df[paper_df[\"0\"].isin(paper_list)]\n",
    "# load the initial input csv\n",
    "initial_input_csv = \"data/processed/3rd_run/citation_df.csv\"\n",
    "# join on \"EID\" column\n",
    "joined_df = pd.merge(paper_df, pd.read_csv(initial_input_csv), how=\"inner\", on=\"0\")\n",
    "# save to data/processed/3rd_run/missing_papers.xlsx\n",
    "# create the directory if it does not exist\n",
    "if not os.path.exists(\"data/processed/3rd_run\"):\n",
    "    os.makedirs(\"data/processed/3rd_run\")\n",
    "joined_df.to_excel(\"data/processed/3rd_run/missing_papers.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "TEMPLATE = \"\"\"\n",
    "Abstract: {abstract}\n",
    "Summary: {summary}\n",
    "Method: {method}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "# define chat and prompt templates\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are research assistant. You will be shown abstract, summary, and method of a paper. Please answer the questions asked by human.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(TEMPLATE),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(client=None, openai_api_key=openai_api_key, temperature=0, model=\"gpt-3.5-turbo\", max_tokens=2000)\n",
    "question_1 = \"\"\"\n",
    "Choose the most relevant physical aspect of the built environment this study examined: landscape, street design, public space, greenery, building design, infrastructure, others. If it's \"others\", please provide the appropriate aspect that the study examined after \"others:\".\n",
    "Example Answer: \n",
    "------\n",
    "Aspect: *XXX*\n",
    "------\n",
    "\"\"\"\n",
    "question_2 = \"\"\"\n",
    "Choose the most relevant human perception this study examined: health, safety, walkability, urban vitality, transportation and mobility, real estate, others. If it's \"others\", please provide the appropriate human perception that the study examined after \"others:\".\n",
    "Example Answer: \n",
    "------\n",
    "Human perception: *XXX*\n",
    "------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 44/394 [01:17<09:46,  1.68s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 12%|█▏        | 47/394 [11:26<8:43:32, 90.53s/it]  Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 24%|██▍       | 95/394 [22:54<09:59,  2.00s/it]    Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 34%|███▍      | 134/394 [33:59<06:50,  1.58s/it]   Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 57%|█████▋    | 225/394 [46:29<04:14,  1.50s/it]    Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 93%|█████████▎| 368/394 [1:00:32<00:41,  1.61s/it] Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-4CVRlps289f2647PKBe4yLX9 on tokens per min. Limit: 160000 / min. Current: 157417 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      " 94%|█████████▍| 370/394 [1:00:39<01:02,  2.62s/it]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 99%|█████████▉| 390/394 [1:11:21<00:07,  1.78s/it]   Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|██████████| 394/394 [1:21:33<00:00, 12.42s/it] \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "if not os.path.exists(\"data/processed/3rd_run/answers.csv\"):\n",
    "    # get abstract\n",
    "    abstract_df = pd.read_csv(\"data/processed/3rd_run/citation_df.csv\")\n",
    "    # get summary\n",
    "    summary_df = pd.read_csv(\"data/processed/3rd_run/summary.csv\")\n",
    "    # get method\n",
    "    method_df = pd.read_csv(\"data/processed/3rd_run/type_of_research.csv\")\n",
    "    # join them on \"0\"\n",
    "    joined_df = pd.merge(abstract_df, summary_df, how=\"inner\", on=\"0\")\n",
    "    joined_df = pd.merge(joined_df, method_df, how=\"inner\", on=\"0\")\n",
    "    # # only use the first 2 rows\n",
    "    # joined_df = joined_df.head(5)\n",
    "    # loop through joined_df with itertruples and save the answers to the dataframe\n",
    "    for row in tqdm(joined_df.itertuples(), total=joined_df.shape[0]):\n",
    "        # get abstract, summary, and method\n",
    "        abstract = row.Abstract\n",
    "        summary = row.summary\n",
    "        method = row.method\n",
    "        answer_1 = llm(chat_template.format_messages(abstract=abstract, summary=summary, method=method, question=question_1))\n",
    "        answer_2 = llm(chat_template.format_messages(abstract=abstract, summary=summary, method=method, question=question_2))\n",
    "        # save the answers to the dataframe\n",
    "        joined_df.loc[row.Index, \"answer_1\"] = answer_1.content\n",
    "        joined_df.loc[row.Index, \"answer_2\"] = answer_2.content\n",
    "    # save the dataframe to data/processed/3rd_run/answers.csv\n",
    "    joined_df.to_csv(\"data/processed/3rd_run/answers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the answers\n",
    "import pandas as pd\n",
    "\n",
    "def clean_answer_1(row):\n",
    "    answer_1 = row.answer_1\n",
    "    abstract = row.Abstract\n",
    "    answer_1 = answer_1.lower().replace(\"aspect: \", \"\")\n",
    "    # if \"greenery\" in answer_1, then replace it with \"greenery\"\n",
    "    if \"green\" in answer_1:\n",
    "        answer_1 = \"greenery\"\n",
    "    elif \"signscapes\" in answer_1 or \"urban function\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"street\" in answer_1:\n",
    "        answer_1 = \"street design\"\n",
    "    elif \"natur\" in answer_1:\n",
    "        answer_1 = \"greenery\"\n",
    "    elif \"urban blight density\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"illuminance\" in answer_1:\n",
    "        answer_1 = \"street design\"\n",
    "    elif \"visual properties of the built environment\" in answer_1:\n",
    "        answer_1 = \"street design\"\n",
    "    elif \"neighborhood\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"urban environment\" in answer_1 and \"natural\" in abstract:\n",
    "        answer_1 = \"greenery\"\n",
    "    elif \"urban environment\" in answer_1 and \"natural\" not in abstract:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"safety\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"urban appearance\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"landscape\" in answer_1:\n",
    "        answer_1 = \"landscape\"\n",
    "    elif \"wet\" in answer_1 or \"blue\" in answer_1 or \"river\" in answer_1 or \"water\" in answer_1:\n",
    "        answer_1 = \"waterscapes\"\n",
    "    elif \"sky\" in answer_1 or \"vegetation\" in answer_1:\n",
    "        answer_1 = \"greenery\"\n",
    "    elif \"pedestrian\" in answer_1 or \"sidewalk\" in answer_1 or \"bike\" in answer_1:\n",
    "        answer_1 = \"street design\"\n",
    "    elif \"alleys\" in answer_1:\n",
    "        answer_1 = \"street design\"\n",
    "    elif \"infrastructure\" in answer_1:\n",
    "        answer_1 = \"infrastructure\"\n",
    "    elif \"environment\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"urban space\" in answer_1 and \"architectural\" in answer_1:\n",
    "        answer_1 = \"building design\"\n",
    "    elif \"urban space\" in answer_1 and \"architectural\" not in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"urban perception\" in answer_1 or \"urban attributes\" in answer_1 or \"urban form\" in answer_1 or \"viewscape\" in answer_1:\n",
    "        answer_1 = \"general urban environment\"\n",
    "    elif \"enclosure\" in answer_1 or \"park\" in answer_1:\n",
    "        answer_1 = \"public space\"\n",
    "    return answer_1\n",
    "# health, safety, walkability, urban vitality, transportation and mobility, real estate, others\n",
    "#TODO Impossible to classify due to too many different answers\n",
    "def clean_answer_2(row):\n",
    "    answer_2 = row.answer_2\n",
    "    abstract = row.Abstract\n",
    "    answer_2 = answer_2.lower().replace(\"human perception: \", \"\")\n",
    "    if \"safe\" in answer_2 or \"fear\" in answer_2 or \"crime\" in answer_2:\n",
    "        answer_2 = \"safety\"\n",
    "    elif \"vitality\" in answer_2 or \"playability\" in answer_2:\n",
    "        answer_2 = \"urban vitality\"\n",
    "    elif \"quali\" in answer_2 or \"aesthetic\" in answer_2 or \"beauty\" in answer_2 or \"visual\" in answer_2 or \"wealth\" in answer_2 \\\n",
    "        or \"appearance\" in answer_2 or \"street views\" in answer_2 or \"attributes\" in answer_2 or \"perception\" in answer_2 \\\n",
    "        or \"atmosphere\" in answer_2:\n",
    "        answer_2 = \"general quality\"\n",
    "    elif \"psycho\" in answer_2 or \"well-being\" in answer_2 or \"mental\" in answer_2 or \"health\" in answer_2 or \"wellbeing\" in answer_2 \\\n",
    "        or \"restor\" in answer_2 or \"emotion\" in answer_2:\n",
    "        answer_2 = \"health\"\n",
    "    elif \"comfortable\" in answer_2:\n",
    "        answer_2 = \"real estate\"\n",
    "    return answer_2\n",
    "\n",
    "answers_df = pd.read_csv(\"data/processed/3rd_run/answers.csv\")\n",
    "# show unique answer_1\n",
    "answers_df[\"answer_1\"] = answers_df.apply(lambda row: clean_answer_1(row), axis=1)\n",
    "# save to data/processed/3rd_run/aspect.csv after renaming answer_1 to aspect\n",
    "answers_df.rename(columns={\"answer_1\": \"improved_aspect\"})[[\"0\", \"improved_aspect\"]].to_csv(\"data/processed/3rd_run/aspect.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tremendous amount of research use questionnaires to obtain individuals’ fear of crime and aggregate it to the neighborhood level to measure the spatial distribution of fear of crime\n",
      " However, the cost of using questionnaires to measure the large-scale spatial distribution of fear of crime is high\n",
      " The built environment is known to influence people’s perceptions, including fear of crime\n",
      " This study develops a machine learning model to link built environment extracted from street view images to fear of crime obtained from questionnaires, and then applies this model to extrapolate fear of crime for neighborhoods without the questionnaires\n",
      " Using massive street view images and a survey among 1,741 residents in 80 neighborhoods in Guangzhou, China, this study developed a novel systematic approach to measuring large-scale spatial fear of crime at the neighborhood level for 1,753 neighborhoods\n",
      " This is the first study to measure fear of crime at the neighborhood level for a metropolitan area of nearly 20 million people\n",
      " The integration of survey data and street view images provides an opportunity to develop a more effective way to measure the spatial distribution of fear of crime\n",
      " This approach could be applied to map other types of perceptions at a spatial resolution of the neighborhood level\n",
      " © The Author(s) 2022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check row with \"blight density\" in answer_1\n",
    "answer_1_example_list = answers_df[answers_df[\"answer_1\"].str.contains(\"point\")][\"Abstract\"].values[0].split(\".\")\n",
    "for answer_1_example in answer_1_example_list:\n",
    "    print(answer_1_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/koichiito/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/koichiito/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "2023-11-03 18:59:10,639 - src.models.write_review - INFO - Module loaded.\n"
     ]
    }
   ],
   "source": [
    "from src.models import predict_model\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# input and output path\n",
    "citation_csv = \"data/external/asreview_dataset_all_visual-urban-perception-2023-07-09-2023-07-17.csv\"\n",
    "complementary_excel = \"data/processed/3rd_run/input_df_with_title_doi_edited.xlsx\"\n",
    "reclibrated_aspect_csv = \"data/processed/3rd_run/aspect.csv\"\n",
    "summary_csv = \"data/processed/3rd_run/summary.csv\"\n",
    "limitation_opportunity_csv = \"data/processed/3rd_run/limitation_future_opportunity.csv\"\n",
    "output_csv_file_path = \"data/processed/3rd_run/review_by_aspect.csv\"\n",
    "predict_model.main(citation_csv, complementary_excel, reclibrated_aspect_csv, summary_csv, limitation_opportunity_csv, output_csv_file_path, openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV...\n",
      "Writing RIS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Author(s) ID` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Issue` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Art. No.` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Page start` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Page end` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Page count` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Cited by` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Link` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Affiliations` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Authors with affiliations` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Author Keywords` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Index Keywords` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Document Type` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Publication Stage` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Open Access` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `Source` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `EID` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n",
      "/Users/koichiito/opt/anaconda3/envs/vis_review/lib/python3.8/site-packages/rispy/writer.py:114: UserWarning: label `exported_notes_1` not exported\n",
      "  warnings.warn(UserWarning(f\"label `{label}` not exported\"))\n"
     ]
    }
   ],
   "source": [
    "# convert csv to ris\n",
    "from src.data.asr_csv2ris import CSV2RISConverter\n",
    "csv_filepath = \"data/external/asreview_dataset_all_visual-urban-perception-2023-07-09-2023-07-17.csv\"\n",
    "ris_filepath = \"data/external/3rd_run/references.ris\"\n",
    "csv2ris = CSV2RISConverter(csv_filepath, ris_filepath)\n",
    "csv2ris.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "from src.models.predict_model import remove_articles_and_prepositions\n",
    "# create a matching table for old and new citations\n",
    "def get_new_latex_citation(author: str, title: str, year: str) -> str:\n",
    "    author_first_name = unidecode.unidecode(author.split(\"., \")[0].split(\" \")[0].lower())\n",
    "    title_first_word = remove_articles_and_prepositions(title).split(\" \")[0].lower().replace(\"-\", \"\")\n",
    "    return f\"{author_first_name}_{title_first_word}_{year}\"\n",
    "\n",
    "def get_old_latex_citation(author: str, title: str, year: str) -> str:\n",
    "    author_first_name = unidecode.unidecode(author.split(\"., \")[0].replace(\" \",\"\").lower())\n",
    "    title_first_word = remove_articles_and_prepositions(title).split(\" \")[0].lower().replace(\"-\", \"\")\n",
    "    return f\"{author_first_name}_{title_first_word}_{year}\"\n",
    "\n",
    "def create_matching_table(df: pd.DataFrame, output_path: str):\n",
    "    df['new_citations'] = df[['Authors', 'Year', 'Title']].apply(\n",
    "        lambda row: get_new_latex_citation(row[\"Authors\"], row[\"Title\"], row[\"Year\"]), axis=1)\n",
    "    df['old_citations'] = df[['Authors', 'Year', 'Title']].apply(\n",
    "        lambda row: get_old_latex_citation(row[\"Authors\"], row[\"Title\"], row[\"Year\"]), axis=1)\n",
    "    # keep only the columns that we need\n",
    "    df = df[[\"new_citations\", \"old_citations\"]]\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "# create a matching table for old and new citations\n",
    "df = pd.read_csv(\"data/external/asreview_dataset_all_visual-urban-perception-2023-07-09-2023-07-17.csv\")\n",
    "output_path = \"data/external/3rd_run/matching_table.csv\"\n",
    "create_matching_table(df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97350"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the matching table to replace the citations in data/external/3rd_run/paper.txt\n",
    "text = open(\"data/external/3rd_run/paper.txt\", \"r\").read()\n",
    "matching_table = pd.read_csv(\"data/external/3rd_run/matching_table.csv\")\n",
    "# replace a list of old citations with a list of new citations\n",
    "old_citations = matching_table[\"old_citations\"].tolist()\n",
    "new_citations = matching_table[\"new_citations\"].tolist()\n",
    "for old_citation, new_citation in zip(old_citations, new_citations):\n",
    "    text = text.replace(old_citation, new_citation)\n",
    "# save to data/external/3rd_run/paper_modified.txt\n",
    "text_file = open(\"data/external/3rd_run/paper_modified.txt\", \"w\")\n",
    "text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vis_review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
